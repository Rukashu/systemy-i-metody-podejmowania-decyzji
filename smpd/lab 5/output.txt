
R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Workspace loaded from C:/Users/User/Desktop/metody podejmowania decyzji/systemy-i-metody-podejmowania-decyzji/smpd/lab 5/.RData]

> library("neuralnet")
Warning message:
pakiet ‘neuralnet’ zosta³ zbudowany w wersji R 3.3.3 
> 
> 
> #Type ?neuralnet for more information on the neuralnet library
> 
> #Generate 5 random numbers uniformly distributed between 0 and 30 (for very good results in such a range)
> #And store them as a dataframe
> traininginput <- as.data.frame(runif(5, min=0, max=30))
> trainingoutput <- (traininginput^3) - (2 * traininginput)
> 
> #Column bind the data into one variable
> trainingdata <- cbind(traininginput,trainingoutput)
> colnames(trainingdata) <- c("Input","Output")
> 
> #Train the neural network
> #Going to have C(5, 3) hidden layers
> #Threshold is a numeric value specifying the threshold for the partial
> #derivatives of the error function as stopping criteria.
> net.myfunction <- neuralnet(Output~Input, trainingdata, hidden=c(5, 3), threshold=0.01)
> print(net.myfunction)
$call
neuralnet(formula = Output ~ Input, data = trainingdata, hidden = c(5, 
    3), threshold = 0.01)

$response
         Output
1 3263.27104904
2   17.26479784
3 1180.07880302
4 6292.28946424
5   13.24337382

$covariate
             [,1]
[1,] 14.877560581
[2,]  2.841733054
[3,] 10.630539323
[4,] 18.497720591
[5,]  2.646520394

$model.list
$model.list$response
[1] "Output"

$model.list$variables
[1] "Input"


$err.fct
function (x, y) 
{
    1/2 * (y - x)^2
}
<environment: 0x0000000009f33d50>
attr(,"type")
[1] "sse"

$act.fct
function (x) 
{
    1/(1 + exp(-x))
}
<environment: 0x0000000009f33d50>
attr(,"type")
[1] "logistic"

$linear.output
[1] TRUE

$data
         Input        Output
1 14.877560581 3263.27104904
2  2.841733054   17.26479784
3 10.630539323 1180.07880302
4 18.497720591 6292.28946424
5  2.646520394   13.24337382

$net.result
$net.result[[1]]
           [,1]
1 3263.27104908
2   15.25408936
3 1180.07880271
4 6292.28946354
5   15.25408936


$weights
$weights[[1]]
$weights[[1]][[1]]
              [,1]          [,2]          [,3]          [,4]         [,5]
[1,]  9.0098767717 -19.721966477 -19.644302502 -18.234032391  7.576740829
[2,] -0.4652636807   2.093705107   3.601874505   2.621865109 11.046190209

$weights[[1]][[2]]
             [,1]          [,2]          [,3]
[1,] -10.39709398  -9.605146443  -9.853721991
[2,] -39.66655825 -38.930887366 -35.548018976
[3,]  17.85418486  13.705456798  17.508798047
[4,]  22.27670881  22.222960646  19.790733924
[5,]  14.10681710  15.539001344  16.789208260
[6,]  -9.67673514  -7.997262135  -7.799942844

$weights[[1]][[3]]
              [,1]
[1,]   15.25408936
[2,] 2092.96698745
[3,] 2091.50480139
[4,] 2092.68520372



$startweights
$startweights[[1]]
$startweights[[1]][[1]]
              [,1]          [,2]         [,3]         [,4]          [,5]
[1,]  0.1658628335 -0.7658304362 -1.128997694 -0.601526957  0.1767408295
[2,] -1.5354574417  0.2333019547  0.428500737 -1.682564876 -0.4863682556

$startweights[[1]][[2]]
               [,1]          [,2]          [,3]
[1,]  0.15409353812  0.3501996890 -0.1674676695
[2,]  2.36619094848  0.5717648790  0.7281119237
[3,]  1.23230100617 -0.8224780672  1.6949734883
[4,] -0.36923513179  0.2112828603 -1.1513648355
[5,] -1.78616712026  0.4608731167  1.2968114230
[6,]  0.01192949851  1.2291611162 -0.8701489354

$startweights[[1]][[3]]
              [,1]
[1,] -0.6531134603
[2,]  1.6089561827
[3,]  0.1501017627
[4,]  1.2010660793



$generalized.weights
$generalized.weights[[1]]
                                   [,1]
1 -0.0001438002647259415246825536849329
2 -0.0000000000000000000000011506797549
3 -0.0010557538240989706914557677563948
4 -0.0000000134892510040599842527798274
5 -0.0000000000000000000000008294272897


$result.matrix
                                       1
error                     4.042962784712
reached.threshold         0.002125699251
steps                 20995.000000000000
Intercept.to.1layhid1     9.009876771733
Input.to.1layhid1        -0.465263680739
Intercept.to.1layhid2   -19.721966477395
Input.to.1layhid2         2.093705107012
Intercept.to.1layhid3   -19.644302502406
Input.to.1layhid3         3.601874504508
Intercept.to.1layhid4   -18.234032391266
Input.to.1layhid4         2.621865109373
Intercept.to.1layhid5     7.576740829477
Input.to.1layhid5        11.046190208918
Intercept.to.2layhid1   -10.397093980578
1layhid.1.to.2layhid1   -39.666558254532
1layhid.2.to.2layhid1    17.854184860542
1layhid.3.to.2layhid1    22.276708806521
1layhid.4.to.2layhid1    14.106817102479
1layhid.5.to.2layhid1    -9.676735140190
Intercept.to.2layhid2    -9.605146442518
1layhid.1.to.2layhid2   -38.930887366141
1layhid.2.to.2layhid2    13.705456797529
1layhid.3.to.2layhid2    22.222960646214
1layhid.4.to.2layhid2    15.539001343662
1layhid.5.to.2layhid2    -7.997262135310
Intercept.to.2layhid3    -9.853721991318
1layhid.1.to.2layhid3   -35.548018975822
1layhid.2.to.2layhid3    17.508798047173
1layhid.3.to.2layhid3    19.790733924402
1layhid.4.to.2layhid3    16.789208259964
1layhid.5.to.2layhid3    -7.799942844196
Intercept.to.Output      15.254089356544
2layhid.1.to.Output    2092.966987451967
2layhid.2.to.Output    2091.504801388400
2layhid.3.to.Output    2092.685203722103

attr(,"class")
[1] "nn"
> 
> #Plot the neural network
> plot(net.myfunction)
> 
> #Test the neural network on some training data
> testdata <- as.data.frame((2:200)*0.5) #Generate some numbers between 1 and 100
> net.results <- compute(net.myfunction, testdata) #Run them through the neural network
> 
> #Lets see what properties net.myfunction has
> ls(net.results)
[1] "net.result" "neurons"   
> 
> #Lets see the results
> print(net.results$net.result)
                [,1]
  [1,]   15.25408936
  [2,]   15.25408936
  [3,]   15.25408936
  [4,]   15.25408936
  [5,]   15.25408936
  [6,]   15.25408936
  [7,]   15.25408936
  [8,]   15.25408936
  [9,]   15.25408936
 [10,]   15.25408936
 [11,]   15.25408936
 [12,]   15.25408936
 [13,]   15.25408942
 [14,]   15.25409811
 [15,]   15.25423108
 [16,]   15.25527662
 [17,]   15.28163241
 [18,]   17.62973298
 [19,]  151.32967269
 [20,]  966.80063017
 [21,] 1564.39997147
 [22,] 1791.09326104
 [23,] 1910.53720702
 [24,] 2007.12814996
 [25,] 2109.83714855
 [26,] 2240.76870018
 [27,] 2440.47583112
 [28,] 2797.37228653
 [29,] 3463.40188040
 [30,] 4502.41812210
 [31,] 5527.38746853
 [32,] 6075.04822726
 [33,] 6247.19055136
 [34,] 6284.95243788
 [35,] 6291.39077626
 [36,] 6292.29067479
 [37,] 6292.39822673
 [38,] 6292.40976804
 [39,] 6292.41094529
 [40,] 6292.41106658
 [41,] 6292.41107996
 [42,] 6292.41108162
 [43,] 6292.41108187
 [44,] 6292.41108191
 [45,] 6292.41108192
 [46,] 6292.41108192
 [47,] 6292.41108192
 [48,] 6292.41108192
 [49,] 6292.41108192
 [50,] 6292.41108192
 [51,] 6292.41108192
 [52,] 6292.41108192
 [53,] 6292.41108192
 [54,] 6292.41108192
 [55,] 6292.41108192
 [56,] 6292.41108192
 [57,] 6292.41108192
 [58,] 6292.41108192
 [59,] 6292.41108192
 [60,] 6292.41108192
 [61,] 6292.41108192
 [62,] 6292.41108192
 [63,] 6292.41108192
 [64,] 6292.41108192
 [65,] 6292.41108192
 [66,] 6292.41108192
 [67,] 6292.41108192
 [68,] 6292.41108192
 [69,] 6292.41108192
 [70,] 6292.41108192
 [71,] 6292.41108192
 [72,] 6292.41108192
 [73,] 6292.41108192
 [74,] 6292.41108192
 [75,] 6292.41108192
 [76,] 6292.41108192
 [77,] 6292.41108192
 [78,] 6292.41108192
 [79,] 6292.41108192
 [80,] 6292.41108192
 [81,] 6292.41108192
 [82,] 6292.41108192
 [83,] 6292.41108192
 [84,] 6292.41108192
 [85,] 6292.41108192
 [86,] 6292.41108192
 [87,] 6292.41108192
 [88,] 6292.41108192
 [89,] 6292.41108192
 [90,] 6292.41108192
 [91,] 6292.41108192
 [92,] 6292.41108192
 [93,] 6292.41108192
 [94,] 6292.41108192
 [95,] 6292.41108192
 [96,] 6292.41108192
 [97,] 6292.41108192
 [98,] 6292.41108192
 [99,] 6292.41108192
[100,] 6292.41108192
[101,] 6292.41108192
[102,] 6292.41108192
[103,] 6292.41108192
[104,] 6292.41108192
[105,] 6292.41108192
[106,] 6292.41108192
[107,] 6292.41108192
[108,] 6292.41108192
[109,] 6292.41108192
[110,] 6292.41108192
[111,] 6292.41108192
[112,] 6292.41108192
[113,] 6292.41108192
[114,] 6292.41108192
[115,] 6292.41108192
[116,] 6292.41108192
[117,] 6292.41108192
[118,] 6292.41108192
[119,] 6292.41108192
[120,] 6292.41108192
[121,] 6292.41108192
[122,] 6292.41108192
[123,] 6292.41108192
[124,] 6292.41108192
[125,] 6292.41108192
[126,] 6292.41108192
[127,] 6292.41108192
[128,] 6292.41108192
[129,] 6292.41108192
[130,] 6292.41108192
[131,] 6292.41108192
[132,] 6292.41108192
[133,] 6292.41108192
[134,] 6292.41108192
[135,] 6292.41108192
[136,] 6292.41108192
[137,] 6292.41108192
[138,] 6292.41108192
[139,] 6292.41108192
[140,] 6292.41108192
[141,] 6292.41108192
[142,] 6292.41108192
[143,] 6292.41108192
[144,] 6292.41108192
[145,] 6292.41108192
[146,] 6292.41108192
[147,] 6292.41108192
[148,] 6292.41108192
[149,] 6292.41108192
[150,] 6292.41108192
[151,] 6292.41108192
[152,] 6292.41108192
[153,] 6292.41108192
[154,] 6292.41108192
[155,] 6292.41108192
[156,] 6292.41108192
[157,] 6292.41108192
[158,] 6292.41108192
[159,] 6292.41108192
[160,] 6292.41108192
[161,] 6292.41108192
[162,] 6292.41108192
[163,] 6292.41108192
[164,] 6292.41108192
[165,] 6292.41108192
[166,] 6292.41108192
[167,] 6292.41108192
[168,] 6292.41108192
[169,] 6292.41108192
[170,] 6292.41108192
[171,] 6292.41108192
[172,] 6292.41108192
[173,] 6292.41108192
[174,] 6292.41108192
[175,] 6292.41108192
[176,] 6292.41108192
[177,] 6292.41108192
[178,] 6292.41108192
[179,] 6292.41108192
[180,] 6292.41108192
[181,] 6292.41108192
[182,] 6292.41108192
[183,] 6292.41108192
[184,] 6292.41108192
[185,] 6292.41108192
[186,] 6292.41108192
[187,] 6292.41108192
[188,] 6292.41108192
[189,] 6292.41108192
[190,] 6292.41108192
[191,] 6292.41108192
[192,] 6292.41108192
[193,] 6292.41108192
[194,] 6292.41108192
[195,] 6292.41108192
[196,] 6292.41108192
[197,] 6292.41108192
[198,] 6292.41108192
[199,] 6292.41108192
> 
> #Lets display a better version of the results
> cleanoutput <- cbind(testdata,(testdata^3) - (2 * testdata),
+                      as.data.frame(net.results$net.result))
> colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
> print(cleanoutput)
    Input Expected Output Neural Net Output
1     1.0          -1.000       15.25408936
2     1.5           0.375       15.25408936
3     2.0           4.000       15.25408936
4     2.5          10.625       15.25408936
5     3.0          21.000       15.25408936
6     3.5          35.875       15.25408936
7     4.0          56.000       15.25408936
8     4.5          82.125       15.25408936
9     5.0         115.000       15.25408936
10    5.5         155.375       15.25408936
11    6.0         204.000       15.25408936
12    6.5         261.625       15.25408936
13    7.0         329.000       15.25408942
14    7.5         406.875       15.25409811
15    8.0         496.000       15.25423108
16    8.5         597.125       15.25527662
17    9.0         711.000       15.28163241
18    9.5         838.375       17.62973298
19   10.0         980.000      151.32967269
20   10.5        1136.625      966.80063017
21   11.0        1309.000     1564.39997147
22   11.5        1497.875     1791.09326104
23   12.0        1704.000     1910.53720702
24   12.5        1928.125     2007.12814996
25   13.0        2171.000     2109.83714855
26   13.5        2433.375     2240.76870018
27   14.0        2716.000     2440.47583112
28   14.5        3019.625     2797.37228653
29   15.0        3345.000     3463.40188040
30   15.5        3692.875     4502.41812210
31   16.0        4064.000     5527.38746853
32   16.5        4459.125     6075.04822726
33   17.0        4879.000     6247.19055136
34   17.5        5324.375     6284.95243788
35   18.0        5796.000     6291.39077626
36   18.5        6294.625     6292.29067479
37   19.0        6821.000     6292.39822673
38   19.5        7375.875     6292.40976804
39   20.0        7960.000     6292.41094529
40   20.5        8574.125     6292.41106658
41   21.0        9219.000     6292.41107996
42   21.5        9895.375     6292.41108162
43   22.0       10604.000     6292.41108187
44   22.5       11345.625     6292.41108191
45   23.0       12121.000     6292.41108192
46   23.5       12930.875     6292.41108192
47   24.0       13776.000     6292.41108192
48   24.5       14657.125     6292.41108192
49   25.0       15575.000     6292.41108192
50   25.5       16530.375     6292.41108192
51   26.0       17524.000     6292.41108192
52   26.5       18556.625     6292.41108192
53   27.0       19629.000     6292.41108192
54   27.5       20741.875     6292.41108192
55   28.0       21896.000     6292.41108192
56   28.5       23092.125     6292.41108192
57   29.0       24331.000     6292.41108192
58   29.5       25613.375     6292.41108192
59   30.0       26940.000     6292.41108192
60   30.5       28311.625     6292.41108192
61   31.0       29729.000     6292.41108192
62   31.5       31192.875     6292.41108192
63   32.0       32704.000     6292.41108192
64   32.5       34263.125     6292.41108192
65   33.0       35871.000     6292.41108192
66   33.5       37528.375     6292.41108192
67   34.0       39236.000     6292.41108192
68   34.5       40994.625     6292.41108192
69   35.0       42805.000     6292.41108192
70   35.5       44667.875     6292.41108192
71   36.0       46584.000     6292.41108192
72   36.5       48554.125     6292.41108192
73   37.0       50579.000     6292.41108192
74   37.5       52659.375     6292.41108192
75   38.0       54796.000     6292.41108192
76   38.5       56989.625     6292.41108192
77   39.0       59241.000     6292.41108192
78   39.5       61550.875     6292.41108192
79   40.0       63920.000     6292.41108192
80   40.5       66349.125     6292.41108192
81   41.0       68839.000     6292.41108192
82   41.5       71390.375     6292.41108192
83   42.0       74004.000     6292.41108192
84   42.5       76680.625     6292.41108192
85   43.0       79421.000     6292.41108192
86   43.5       82225.875     6292.41108192
87   44.0       85096.000     6292.41108192
88   44.5       88032.125     6292.41108192
89   45.0       91035.000     6292.41108192
90   45.5       94105.375     6292.41108192
91   46.0       97244.000     6292.41108192
92   46.5      100451.625     6292.41108192
93   47.0      103729.000     6292.41108192
94   47.5      107076.875     6292.41108192
95   48.0      110496.000     6292.41108192
96   48.5      113987.125     6292.41108192
97   49.0      117551.000     6292.41108192
98   49.5      121188.375     6292.41108192
99   50.0      124900.000     6292.41108192
100  50.5      128686.625     6292.41108192
101  51.0      132549.000     6292.41108192
102  51.5      136487.875     6292.41108192
103  52.0      140504.000     6292.41108192
104  52.5      144598.125     6292.41108192
105  53.0      148771.000     6292.41108192
106  53.5      153023.375     6292.41108192
107  54.0      157356.000     6292.41108192
108  54.5      161769.625     6292.41108192
109  55.0      166265.000     6292.41108192
110  55.5      170842.875     6292.41108192
111  56.0      175504.000     6292.41108192
112  56.5      180249.125     6292.41108192
113  57.0      185079.000     6292.41108192
114  57.5      189994.375     6292.41108192
115  58.0      194996.000     6292.41108192
116  58.5      200084.625     6292.41108192
117  59.0      205261.000     6292.41108192
118  59.5      210525.875     6292.41108192
119  60.0      215880.000     6292.41108192
120  60.5      221324.125     6292.41108192
121  61.0      226859.000     6292.41108192
122  61.5      232485.375     6292.41108192
123  62.0      238204.000     6292.41108192
124  62.5      244015.625     6292.41108192
125  63.0      249921.000     6292.41108192
126  63.5      255920.875     6292.41108192
127  64.0      262016.000     6292.41108192
128  64.5      268207.125     6292.41108192
129  65.0      274495.000     6292.41108192
130  65.5      280880.375     6292.41108192
131  66.0      287364.000     6292.41108192
132  66.5      293946.625     6292.41108192
133  67.0      300629.000     6292.41108192
134  67.5      307411.875     6292.41108192
135  68.0      314296.000     6292.41108192
136  68.5      321282.125     6292.41108192
137  69.0      328371.000     6292.41108192
138  69.5      335563.375     6292.41108192
139  70.0      342860.000     6292.41108192
140  70.5      350261.625     6292.41108192
141  71.0      357769.000     6292.41108192
142  71.5      365382.875     6292.41108192
143  72.0      373104.000     6292.41108192
144  72.5      380933.125     6292.41108192
145  73.0      388871.000     6292.41108192
146  73.5      396918.375     6292.41108192
147  74.0      405076.000     6292.41108192
148  74.5      413344.625     6292.41108192
149  75.0      421725.000     6292.41108192
150  75.5      430217.875     6292.41108192
151  76.0      438824.000     6292.41108192
152  76.5      447544.125     6292.41108192
153  77.0      456379.000     6292.41108192
154  77.5      465329.375     6292.41108192
155  78.0      474396.000     6292.41108192
156  78.5      483579.625     6292.41108192
157  79.0      492881.000     6292.41108192
158  79.5      502300.875     6292.41108192
159  80.0      511840.000     6292.41108192
160  80.5      521499.125     6292.41108192
161  81.0      531279.000     6292.41108192
162  81.5      541180.375     6292.41108192
163  82.0      551204.000     6292.41108192
164  82.5      561350.625     6292.41108192
165  83.0      571621.000     6292.41108192
166  83.5      582015.875     6292.41108192
167  84.0      592536.000     6292.41108192
168  84.5      603182.125     6292.41108192
169  85.0      613955.000     6292.41108192
170  85.5      624855.375     6292.41108192
171  86.0      635884.000     6292.41108192
172  86.5      647041.625     6292.41108192
173  87.0      658329.000     6292.41108192
174  87.5      669746.875     6292.41108192
175  88.0      681296.000     6292.41108192
176  88.5      692977.125     6292.41108192
177  89.0      704791.000     6292.41108192
178  89.5      716738.375     6292.41108192
179  90.0      728820.000     6292.41108192
180  90.5      741036.625     6292.41108192
181  91.0      753389.000     6292.41108192
182  91.5      765877.875     6292.41108192
183  92.0      778504.000     6292.41108192
184  92.5      791268.125     6292.41108192
185  93.0      804171.000     6292.41108192
186  93.5      817213.375     6292.41108192
187  94.0      830396.000     6292.41108192
188  94.5      843719.625     6292.41108192
189  95.0      857185.000     6292.41108192
190  95.5      870792.875     6292.41108192
191  96.0      884544.000     6292.41108192
192  96.5      898439.125     6292.41108192
193  97.0      912479.000     6292.41108192
194  97.5      926664.375     6292.41108192
195  98.0      940996.000     6292.41108192
196  98.5      955474.625     6292.41108192
197  99.0      970101.000     6292.41108192
198  99.5      984875.875     6292.41108192
199 100.0      999800.000     6292.41108192